{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "hat = prediction_train\n",
    "dfData = hat.corr()\n",
    "plt.subplots(figsize=(15, 15)) # 设置画面大小\n",
    "p=sns.heatmap(dfData, annot=True, vmax=1, square=True,yticklabels=hat.columns,xticklabels=hat.columns, cmap=\"RdBu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p=sns.boxplot(data=new_train_X[\"AlogP\"]) #左图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=3)\n",
    "X_std_pca=pca.fit_transform(train_x)\n",
    "Y=pd.DataFrame(X_std_pca,columns=[\"new_pca_\"+str(i) for i in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "n_fold = 5\n",
    "\n",
    "Train = pd.read_csv(\"D:/DC/Molecule_prediction_20200312/train_0312.csv\")\n",
    "\n",
    "##############################################################################################\n",
    "train = Train[[i for i in Train.columns if i not in [\"Features\", \"ID\"]]]\n",
    "# 均值填充none\n",
    "train_x = train.drop(columns=[\"Label\"])\n",
    "\n",
    "\n",
    "#################################################################################################################\n",
    "# -------------------------------------------------特征工程 ---------------------------------------#\n",
    "# 特征 1 \"Features\"\n",
    "def get_Features(Train, train_x):\n",
    "    globals = {\n",
    "            'nan': 0\n",
    "    }\n",
    "    new_col = Train[\"Features\"][train_x.index].apply(lambda x: eval(x, globals))\n",
    "    X = pd.DataFrame(list(new_col.values))\n",
    "    train_x = pd.concat([train_x, X], axis=1)\n",
    "\n",
    "    train_x[\"Features_p\"]       = np.sqrt(np.power(X, 2).sum(axis=1))\n",
    "    train_x[\"Features_mean\"]    = X.mean(axis=1)\n",
    "    train_x[\"Features_min\"]     = X.min(axis=1)\n",
    "    train_x[\"Features_max\"]     = X.max(axis=1)\n",
    "    train_x[\"Features_sum\"]     = X.sum(axis=1)\n",
    "    train_x['Molecular weight'] = np.log1p(train_x['Molecular weight'])\n",
    "    train_x['AlogP']            = np.log1p(train_x['AlogP'])\n",
    "    train_x[\"violations\"]       = train_x[[\"Molecular weight\", \"RO5_violations\"]].mean(axis=1)\n",
    "    \n",
    "    \n",
    "    return train_x.fillna(train_x.median())[iport_list]\n",
    "    \n",
    "\n",
    "########################################################################\n",
    "## 获取测试集数据\n",
    "def get_pre():\n",
    "    Test = pd.read_csv(\"D:/DC/Molecule_prediction_20200312/test_noLabel_0312.csv\")\n",
    "    test = Test[[i for i in Test.columns if i not in [\"Features\",\"ID\"]]]\n",
    "    \n",
    "    return get_Features(Test, test),Test[[\"ID\"]]\n",
    "\n",
    "Test_LIST = get_pre()\n",
    "Test=Test_LIST[0]\n",
    "prediction_test=Test_LIST[1]\n",
    "\n",
    "##############################################################################################\n",
    "# 训练集数据\n",
    "new_train_X = get_Features(Train, train_x)\n",
    "new_train_Y = train[\"Label\"]\n",
    "\n",
    "prediction_train=Train.loc[:,[\"ID\"]].iloc[new_train_Y.index]\n",
    "##############################################################################################\n",
    "#   测试\n",
    "##############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train[\"Label_3\"]=0\n",
    "prediction_test[\"Label_3\"]=0\n",
    "\n",
    "\n",
    "XGB_model = XGBRegressor(\n",
    "                              max_depth=10,\n",
    "                              learning_rate=0.135,\n",
    "                              n_estimators=10000000,\n",
    "                              subsample=0.8,\n",
    "                              colsample_bytree=0.6,\n",
    "                              reg_alpha=3.25,\n",
    "                              reg_lambda=3.5,\n",
    "                              )\n",
    "\n",
    "# 进行交叉验证\n",
    "kfold = KFold(n_splits=n_fold)\n",
    "for train_index, test_index in kfold.split(new_train_X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "    train_x, test_x = new_train_X.iloc[train_index], new_train_X.iloc[test_index]\n",
    "    train_y, test_y = new_train_Y.iloc[train_index], new_train_Y.iloc[test_index]\n",
    "    \n",
    "    group_col=list(train_x.columns)\n",
    "    train_x[\"Label\"]=train_y\n",
    "    Features=train_x.groupby(by=group_col,as_index=False).mean()\n",
    "    train_x=Features.drop(columns=\"Label\")\n",
    "    train_y = Features[\"Label\"]\n",
    "    \n",
    "\n",
    "    XGB_model.fit(train_x, train_y,\n",
    "                  eval_set=[(train_x, train_y), (test_x, test_y)],\n",
    "                  eval_metric='rmse',\n",
    "                  verbose=500,\n",
    "                  early_stopping_rounds=50)\n",
    "    \n",
    "    prediction_test[\"Label_3\"] += XGB_model.predict(Test) / n_fold\n",
    "    prediction_train[\"Label_3\"] += XGB_model.predict(new_train_X) / n_fold    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [1385 1386 1387 ... 6921 6922 6923] TEST: [   0    1    2 ... 1382 1383 1384]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\my\\mydata\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[500]\ttraining's rmse: 0.588977\tvalid_1's rmse: 2.16431\n",
      "Early stopping, best iteration is:\n",
      "[770]\ttraining's rmse: 0.369336\tvalid_1's rmse: 2.15527\n",
      "TRAIN: [   0    1    2 ... 6921 6922 6923] TEST: [1385 1386 1387 ... 2767 2768 2769]\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[500]\ttraining's rmse: 0.603588\tvalid_1's rmse: 2.28444\n",
      "Early stopping, best iteration is:\n",
      "[782]\ttraining's rmse: 0.383332\tvalid_1's rmse: 2.27057\n",
      "TRAIN: [   0    1    2 ... 6921 6922 6923] TEST: [2770 2771 2772 ... 4152 4153 4154]\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[500]\ttraining's rmse: 0.579383\tvalid_1's rmse: 2.28572\n",
      "Early stopping, best iteration is:\n",
      "[700]\ttraining's rmse: 0.403927\tvalid_1's rmse: 2.26886\n",
      "TRAIN: [   0    1    2 ... 6921 6922 6923] TEST: [4155 4156 4157 ... 5537 5538 5539]\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[500]\ttraining's rmse: 0.591051\tvalid_1's rmse: 2.16027\n",
      "Early stopping, best iteration is:\n",
      "[570]\ttraining's rmse: 0.516961\tvalid_1's rmse: 2.15924\n",
      "TRAIN: [   0    1    2 ... 5537 5538 5539] TEST: [5540 5541 5542 ... 6921 6922 6923]\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[500]\ttraining's rmse: 0.594103\tvalid_1's rmse: 2.25722\n",
      "Early stopping, best iteration is:\n",
      "[699]\ttraining's rmse: 0.418905\tvalid_1's rmse: 2.24012\n"
     ]
    }
   ],
   "source": [
    "prediction_train[\"Label_1\"]=0\n",
    "prediction_test[\"Label_1\"]=0\n",
    "\n",
    "\n",
    "lgb_model = LGBMRegressor(max_depth=6,\n",
    "                              learning_rate=0.135,\n",
    "                              boosting_type='gbdt',\n",
    "                              # min_data_in_leaf=30,\n",
    "                              n_estimators=100000,\n",
    "                              subsample=0.79,\n",
    "                              colsample_bytree=0.55,\n",
    "                              metric='rmse',\n",
    "                              num_leaves=195,\n",
    "                              reg_alpha=3.25,\n",
    "                              reg_lambda=3.5,\n",
    "                              )\n",
    "\n",
    "# 进行交叉验证\n",
    "kfold = KFold(n_splits=n_fold)\n",
    "for train_index, test_index in kfold.split(new_train_X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "    train_x, test_x = new_train_X.iloc[train_index], new_train_X.iloc[test_index]\n",
    "    train_y, test_y = new_train_Y.iloc[train_index], new_train_Y.iloc[test_index]\n",
    "    \n",
    "    group_col=list(train_x.columns)\n",
    "    train_x[\"Label\"]=train_y\n",
    "    Features=train_x.groupby(by=group_col,as_index=False).mean()\n",
    "    train_x=Features.drop(columns=\"Label\")\n",
    "    train_y = Features[\"Label\"]\n",
    "    \n",
    "    \n",
    "    lgb_model.fit(train_x, train_y,\n",
    "                  eval_set=[(train_x, train_y), (test_x, test_y)],\n",
    "                  eval_metric='rmse',\n",
    "                  verbose=500,\n",
    "                  early_stopping_rounds=50)\n",
    "    \n",
    "    prediction_test[\"Label_1\"] += lgb_model.predict(Test, num_iteration=lgb_model.best_iteration_) / n_fold\n",
    "    prediction_train[\"Label_1\"] += lgb_model.predict(new_train_X, num_iteration=lgb_model.best_iteration_) / n_fold    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [1385 1386 1387 ... 6921 6922 6923] TEST: [   0    1    2 ... 1382 1383 1384]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\my\\mydata\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4.4515421\ttest: 4.4515421\ttest1: 4.9602790\tbest: 4.9602790 (0)\ttotal: 284ms\tremaining: 32d 21h 52m 17s\n",
      "500:\tlearn: 0.2684404\ttest: 0.2684404\ttest1: 2.1969747\tbest: 2.1964377 (485)\ttotal: 2m 48s\tremaining: 38d 21h 48m 53s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 2.196437703\n",
      "bestIteration = 485\n",
      "\n",
      "Shrink model to first 486 iterations.\n",
      "TRAIN: [   0    1    2 ... 6921 6922 6923] TEST: [1385 1386 1387 ... 2767 2768 2769]\n",
      "0:\tlearn: 4.4333033\ttest: 4.4333033\ttest1: 4.9026824\tbest: 4.9026824 (0)\ttotal: 352ms\tremaining: 40d 16h 23m 23s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 2.328009767\n",
      "bestIteration = 447\n",
      "\n",
      "Shrink model to first 448 iterations.\n",
      "TRAIN: [   0    1    2 ... 6921 6922 6923] TEST: [2770 2771 2772 ... 4152 4153 4154]\n",
      "0:\tlearn: 4.4109724\ttest: 4.4109724\ttest1: 4.9743574\tbest: 4.9743574 (0)\ttotal: 356ms\tremaining: 41d 4h 52m 16s\n",
      "500:\tlearn: 0.2494920\ttest: 0.2494920\ttest1: 2.3091234\tbest: 2.3091234 (500)\ttotal: 2m 35s\tremaining: 35d 21h 21m 37s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 2.307194782\n",
      "bestIteration = 598\n",
      "\n",
      "Shrink model to first 599 iterations.\n",
      "TRAIN: [   0    1    2 ... 6921 6922 6923] TEST: [4155 4156 4157 ... 5537 5538 5539]\n",
      "0:\tlearn: 4.4581933\ttest: 4.4581933\ttest1: 4.8547355\tbest: 4.8547355 (0)\ttotal: 290ms\tremaining: 33d 14h 35m 38s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 2.196719573\n",
      "bestIteration = 432\n",
      "\n",
      "Shrink model to first 433 iterations.\n",
      "TRAIN: [   0    1    2 ... 5537 5538 5539] TEST: [5540 5541 5542 ... 6921 6922 6923]\n",
      "0:\tlearn: 4.4728532\ttest: 4.4728532\ttest1: 4.8362347\tbest: 4.8362347 (0)\ttotal: 292ms\tremaining: 33d 18h 4m 35s\n",
      "500:\tlearn: 0.2514925\ttest: 0.2514925\ttest1: 2.2802106\tbest: 2.2800316 (495)\ttotal: 2m 32s\tremaining: 35d 7h 9m 56s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 2.273790078\n",
      "bestIteration = 671\n",
      "\n",
      "Shrink model to first 672 iterations.\n"
     ]
    }
   ],
   "source": [
    "prediction_train[\"Label_2\"]=0\n",
    "prediction_test[\"Label_2\"]=0\n",
    "\n",
    "ctb_model = CatBoostRegressor(\n",
    "                              max_depth=10,\n",
    "                              learning_rate=0.135,\n",
    "                              n_estimators=10000000,\n",
    "                              subsample=0.8, \n",
    "                              eval_metric='RMSE',\n",
    "                              )\n",
    "\n",
    "# 进行交叉验证\n",
    "kfold = KFold(n_splits=n_fold)\n",
    "for train_index, test_index in kfold.split(new_train_X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    " \n",
    "    train_x, test_x = new_train_X.iloc[train_index], new_train_X.iloc[test_index]\n",
    "    train_y, test_y = new_train_Y.iloc[train_index], new_train_Y.iloc[test_index]\n",
    "    \n",
    "    group_col=list(train_x.columns)\n",
    "    train_x[\"Label\"]=train_y\n",
    "    Features=train_x.groupby(by=group_col,as_index=False).mean()\n",
    "    train_x=Features.drop(columns=\"Label\")\n",
    "    train_y = Features[\"Label\"]\n",
    "    \n",
    "\n",
    "    ctb_model.fit(train_x, train_y,\n",
    "                  eval_set=[(train_x, train_y), (test_x, test_y)],\n",
    "                  verbose=500,\n",
    "                  early_stopping_rounds=50)\n",
    "    \n",
    "    prediction_test[\"Label_2\"] += ctb_model.predict(Test) / n_fold\n",
    "    prediction_train[\"Label_2\"] += ctb_model.predict(new_train_X) / n_fold    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [1385 1386 1387 ... 6921 6922 6923] TEST: [   0    1    2 ... 1382 1383 1384]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\my\\mydata\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.421846396824024 8.027281084149134\n",
      "TRAIN: [   0    1    2 ... 6921 6922 6923] TEST: [1385 1386 1387 ... 2767 2768 2769]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\my\\mydata\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.276572828590143 8.450081395849597\n",
      "TRAIN: [   0    1    2 ... 6921 6922 6923] TEST: [2770 2771 2772 ... 4152 4153 4154]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\my\\mydata\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.23387353553717 8.882818825447496\n",
      "TRAIN: [   0    1    2 ... 6921 6922 6923] TEST: [4155 4156 4157 ... 5537 5538 5539]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\my\\mydata\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.654055822072455 7.717326104178693\n",
      "TRAIN: [   0    1    2 ... 5537 5538 5539] TEST: [5540 5541 5542 ... 6921 6922 6923]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\my\\mydata\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.22145116906087 8.129527468743301\n"
     ]
    }
   ],
   "source": [
    "prediction_train[\"Label_4\"]=0\n",
    "prediction_test[\"Label_4\"]=0\n",
    "gbdt=GradientBoostingRegressor(\n",
    "    learning_rate=0.135,\n",
    "    n_estimators=100,\n",
    "    min_samples_leaf=100,\n",
    "    max_depth=6,\n",
    "    alpha=0.9,\n",
    ")\n",
    "\n",
    "# 进行交叉验证\n",
    "kfold = KFold(n_splits=n_fold)\n",
    "for train_index, test_index in kfold.split(new_train_X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "    train_x, test_x = new_train_X.iloc[train_index], new_train_X.iloc[test_index]\n",
    "    train_y, test_y = new_train_Y.iloc[train_index], new_train_Y.iloc[test_index]\n",
    "    \n",
    "    group_col=list(train_x.columns)\n",
    "    train_x[\"Label\"]=train_y\n",
    "    Features=train_x.groupby(by=group_col,as_index=False).mean()\n",
    "    train_x=Features.drop(columns=\"Label\")\n",
    "    train_y = Features[\"Label\"]\n",
    "    \n",
    "\n",
    "    gbdt.fit(train_x, train_y)\n",
    "    \n",
    "    print(mean_squared_error(gbdt.predict(train_x) ,train_y ),np.sqrt(mean_squared_error(gbdt.predict(test_x) ,test_y )))\n",
    "    prediction_test[\"Label_4\"] += gbdt.predict(Test) / n_fold\n",
    "    prediction_train[\"Label_4\"] += gbdt.predict(new_train_X) / n_fold    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 当前最高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>test_0</td>\n",
       "      <td>8.861174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>test_1</td>\n",
       "      <td>9.827020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>test_2</td>\n",
       "      <td>4.831922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>test_3</td>\n",
       "      <td>11.412235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>test_4</td>\n",
       "      <td>8.084248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1726</td>\n",
       "      <td>test_1726</td>\n",
       "      <td>6.455287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1727</td>\n",
       "      <td>test_1727</td>\n",
       "      <td>-3.265455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1728</td>\n",
       "      <td>test_1728</td>\n",
       "      <td>7.959414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1729</td>\n",
       "      <td>test_1729</td>\n",
       "      <td>2.320193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>test_1730</td>\n",
       "      <td>-0.626785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1731 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID      Label\n",
       "0        test_0   8.861174\n",
       "1        test_1   9.827020\n",
       "2        test_2   4.831922\n",
       "3        test_3  11.412235\n",
       "4        test_4   8.084248\n",
       "...         ...        ...\n",
       "1726  test_1726   6.455287\n",
       "1727  test_1727  -3.265455\n",
       "1728  test_1728   7.959414\n",
       "1729  test_1729   2.320193\n",
       "1730  test_1730  -0.626785\n",
       "\n",
       "[1731 rows x 2 columns]"
      ]
     },
     "execution_count": 899,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>test_0</td>\n",
       "      <td>8.908935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>test_1</td>\n",
       "      <td>9.767433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>test_2</td>\n",
       "      <td>4.986898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>test_3</td>\n",
       "      <td>11.443759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>test_4</td>\n",
       "      <td>8.167540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1726</td>\n",
       "      <td>test_1726</td>\n",
       "      <td>6.520634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1727</td>\n",
       "      <td>test_1727</td>\n",
       "      <td>-3.245663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1728</td>\n",
       "      <td>test_1728</td>\n",
       "      <td>7.925347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1729</td>\n",
       "      <td>test_1729</td>\n",
       "      <td>2.368767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>test_1730</td>\n",
       "      <td>-0.521274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1731 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID      Label\n",
       "0        test_0   8.908935\n",
       "1        test_1   9.767433\n",
       "2        test_2   4.986898\n",
       "3        test_3  11.443759\n",
       "4        test_4   8.167540\n",
       "...         ...        ...\n",
       "1726  test_1726   6.520634\n",
       "1727  test_1727  -3.245663\n",
       "1728  test_1728   7.925347\n",
       "1729  test_1729   2.368767\n",
       "1730  test_1730  -0.521274\n",
       "\n",
       "[1731 rows x 2 columns]"
      ]
     },
     "execution_count": 892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_3</th>\n",
       "      <th>Label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8.688818</td>\n",
       "      <td>9.140424</td>\n",
       "      <td>8.977523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12.858081</td>\n",
       "      <td>12.871333</td>\n",
       "      <td>13.021469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10.237186</td>\n",
       "      <td>10.313701</td>\n",
       "      <td>10.172875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.339184</td>\n",
       "      <td>0.342090</td>\n",
       "      <td>0.515741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.064605</td>\n",
       "      <td>0.367019</td>\n",
       "      <td>0.156104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6919</td>\n",
       "      <td>1.879610</td>\n",
       "      <td>2.146698</td>\n",
       "      <td>2.142588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6920</td>\n",
       "      <td>13.063646</td>\n",
       "      <td>13.009355</td>\n",
       "      <td>13.147774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6921</td>\n",
       "      <td>11.434937</td>\n",
       "      <td>11.597177</td>\n",
       "      <td>11.393089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6922</td>\n",
       "      <td>5.398584</td>\n",
       "      <td>5.348925</td>\n",
       "      <td>5.571958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6923</td>\n",
       "      <td>9.887765</td>\n",
       "      <td>10.061875</td>\n",
       "      <td>10.290479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6924 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Label_1    Label_3    Label_2\n",
       "0      8.688818   9.140424   8.977523\n",
       "1     12.858081  12.871333  13.021469\n",
       "2     10.237186  10.313701  10.172875\n",
       "3      0.339184   0.342090   0.515741\n",
       "4     -0.064605   0.367019   0.156104\n",
       "...         ...        ...        ...\n",
       "6919   1.879610   2.146698   2.142588\n",
       "6920  13.063646  13.009355  13.147774\n",
       "6921  11.434937  11.597177  11.393089\n",
       "6922   5.398584   5.348925   5.571958\n",
       "6923   9.887765  10.061875  10.290479\n",
       "\n",
       "[6924 rows x 3 columns]"
      ]
     },
     "execution_count": 894,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\my\\mydata\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [1385 1386 1387 ... 6921 6922 6923] TEST: [   0    1    2 ... 1382 1383 1384]\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's rmse: 1.10518\tvalid_1's rmse: 1.14381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\my\\mydata\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    2 ... 6921 6922 6923] TEST: [1385 1386 1387 ... 2767 2768 2769]\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's rmse: 1.08435\tvalid_1's rmse: 1.22024\n",
      "TRAIN: [   0    1    2 ... 6921 6922 6923] TEST: [2770 2771 2772 ... 4152 4153 4154]\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's rmse: 1.10416\tvalid_1's rmse: 1.15151\n",
      "TRAIN: [   0    1    2 ... 6921 6922 6923] TEST: [4155 4156 4157 ... 5537 5538 5539]\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's rmse: 1.1186\tvalid_1's rmse: 1.10355\n",
      "TRAIN: [   0    1    2 ... 5537 5538 5539] TEST: [5540 5541 5542 ... 6921 6922 6923]\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's rmse: 1.10748\tvalid_1's rmse: 1.12918\n"
     ]
    }
   ],
   "source": [
    "# pre=prediction_test[[\"ID\"]]\n",
    "pre[\"Label\"]=0\n",
    "# prediction_train=prediction_train.drop(columns=\"ID\")\n",
    "# prediction_test=prediction_test.drop(columns=\"ID\")\n",
    "\n",
    "\n",
    "lgb_model = LGBMRegressor(max_depth=6,\n",
    "                              learning_rate=0.135,\n",
    "                              boosting_type='gbdt',\n",
    "                              n_estimators=10000000,\n",
    "                              subsample=0.79,\n",
    "                              colsample_bytree=0.55,\n",
    "                              metric='rmse',\n",
    "                              num_leaves=195,\n",
    "                              reg_alpha=3.25,\n",
    "                              reg_lambda=3.5,\n",
    "                              )\n",
    "\n",
    "# 进行交叉验证\n",
    "kfold = KFold(n_splits=n_fold)\n",
    "for train_index, test_index in kfold.split(prediction_train):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "    train_x, test_x = prediction_train.iloc[train_index], prediction_train.iloc[test_index]\n",
    "    train_y, test_y = new_train_Y.iloc[train_index], new_train_Y.iloc[test_index]\n",
    "\n",
    "    lgb_model.fit(train_x, train_y,\n",
    "                  eval_set=[(train_x, train_y), (test_x, test_y)],\n",
    "                  eval_metric='rmse',\n",
    "                  verbose=500,\n",
    "                  early_stopping_rounds=50)\n",
    "    \n",
    "    pre[\"Label\"] += lgb_model.predict(prediction_test, num_iteration=lgb_model.best_iteration_) / n_fold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保持预测数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.to_csv('D:/DC/pre_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除不重要的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1553.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>121.042498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>477.288241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>6459.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        importance\n",
       "count  1553.000000\n",
       "mean    121.042498\n",
       "std     477.288241\n",
       "min       2.000000\n",
       "25%      29.000000\n",
       "50%      49.000000\n",
       "75%      81.000000\n",
       "max    6459.000000"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iport.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>3178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>79.620516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>465.407342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>9572.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        importance\n",
       "count  3178.000000\n",
       "mean     79.620516\n",
       "std     465.407342\n",
       "min       0.000000\n",
       "25%       6.000000\n",
       "50%      21.000000\n",
       "75%      54.000000\n",
       "max    9572.000000"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iport.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iport=pd.DataFrame({\n",
    "    'column': train_x.columns,\n",
    "    'importance': lgb_model.feature_importances_,\n",
    "}).sort_values(ascending=False, by=\"importance\")\n",
    "\n",
    "iport_list=iport[iport[\"importance\"]>iport.describe().loc[\"50%\"].values[0]][\"column\"].values\n",
    "len(iport_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\my\\mydata\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Label'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-322-0bec462f06cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Label_3\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\my\\mydata\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\my\\mydata\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Label'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(len(prediction_train[\"Label\"])), prediction_train[\"Label_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AlogP</th>\n",
       "      <th>3166</th>\n",
       "      <th>3154</th>\n",
       "      <th>3152</th>\n",
       "      <th>3157</th>\n",
       "      <th>3153</th>\n",
       "      <th>3156</th>\n",
       "      <th>3161</th>\n",
       "      <th>Features_mean</th>\n",
       "      <th>3159</th>\n",
       "      <th>...</th>\n",
       "      <th>2933</th>\n",
       "      <th>479</th>\n",
       "      <th>1428</th>\n",
       "      <th>2661</th>\n",
       "      <th>2917</th>\n",
       "      <th>2053</th>\n",
       "      <th>1776</th>\n",
       "      <th>1120</th>\n",
       "      <th>673</th>\n",
       "      <th>1362</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.525458</td>\n",
       "      <td>56.15</td>\n",
       "      <td>2.576923</td>\n",
       "      <td>1.230769</td>\n",
       "      <td>0.251390</td>\n",
       "      <td>1.961538</td>\n",
       "      <td>0.494533</td>\n",
       "      <td>134</td>\n",
       "      <td>0.463077</td>\n",
       "      <td>-0.494533</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.520162</td>\n",
       "      <td>65.54</td>\n",
       "      <td>2.470588</td>\n",
       "      <td>1.029412</td>\n",
       "      <td>0.271962</td>\n",
       "      <td>1.794118</td>\n",
       "      <td>0.349011</td>\n",
       "      <td>180</td>\n",
       "      <td>0.599497</td>\n",
       "      <td>-0.349011</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.577560</td>\n",
       "      <td>87.28</td>\n",
       "      <td>2.210526</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.572596</td>\n",
       "      <td>1.631579</td>\n",
       "      <td>0.572596</td>\n",
       "      <td>204</td>\n",
       "      <td>0.706570</td>\n",
       "      <td>-0.405788</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.442192</td>\n",
       "      <td>41.57</td>\n",
       "      <td>2.611111</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>0.250825</td>\n",
       "      <td>1.944444</td>\n",
       "      <td>0.378793</td>\n",
       "      <td>98</td>\n",
       "      <td>0.346830</td>\n",
       "      <td>-0.378793</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.501739</td>\n",
       "      <td>54.37</td>\n",
       "      <td>2.210526</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.310186</td>\n",
       "      <td>1.578947</td>\n",
       "      <td>0.480788</td>\n",
       "      <td>96</td>\n",
       "      <td>0.330614</td>\n",
       "      <td>-0.480788</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6919</td>\n",
       "      <td>0.509485</td>\n",
       "      <td>30.49</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.134568</td>\n",
       "      <td>1.904762</td>\n",
       "      <td>0.492659</td>\n",
       "      <td>110</td>\n",
       "      <td>0.367612</td>\n",
       "      <td>-0.492659</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6920</td>\n",
       "      <td>0.575364</td>\n",
       "      <td>57.46</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.131873</td>\n",
       "      <td>1.638889</td>\n",
       "      <td>0.495895</td>\n",
       "      <td>194</td>\n",
       "      <td>0.626327</td>\n",
       "      <td>-0.495895</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6921</td>\n",
       "      <td>0.554738</td>\n",
       "      <td>67.94</td>\n",
       "      <td>2.785714</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.229711</td>\n",
       "      <td>1.928571</td>\n",
       "      <td>0.370225</td>\n",
       "      <td>140</td>\n",
       "      <td>0.513132</td>\n",
       "      <td>-0.370225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6922</td>\n",
       "      <td>0.520162</td>\n",
       "      <td>58.64</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.409509</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.446694</td>\n",
       "      <td>156</td>\n",
       "      <td>0.510804</td>\n",
       "      <td>-0.446694</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6923</td>\n",
       "      <td>0.524467</td>\n",
       "      <td>83.91</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.341223</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.480602</td>\n",
       "      <td>160</td>\n",
       "      <td>0.577548</td>\n",
       "      <td>-0.480602</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6924 rows × 756 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AlogP   3166      3154      3152      3157      3153      3156  3161  \\\n",
       "0     0.525458  56.15  2.576923  1.230769  0.251390  1.961538  0.494533   134   \n",
       "1     0.520162  65.54  2.470588  1.029412  0.271962  1.794118  0.349011   180   \n",
       "2     0.577560  87.28  2.210526  0.973684  0.572596  1.631579  0.572596   204   \n",
       "3     0.442192  41.57  2.611111  1.277778  0.250825  1.944444  0.378793    98   \n",
       "4     0.501739  54.37  2.210526  0.947368  0.310186  1.578947  0.480788    96   \n",
       "...        ...    ...       ...       ...       ...       ...       ...   ...   \n",
       "6919  0.509485  30.49  2.714286  1.142857  0.134568  1.904762  0.492659   110   \n",
       "6920  0.575364  57.46  2.222222  0.972222  0.131873  1.638889  0.495895   194   \n",
       "6921  0.554738  67.94  2.785714  1.071429  0.229711  1.928571  0.370225   140   \n",
       "6922  0.520162  58.64  2.357143  1.142857  0.409509  1.750000  0.446694   156   \n",
       "6923  0.524467  83.91  2.466667  1.166667  0.341223  1.833333  0.480602   160   \n",
       "\n",
       "      Features_mean      3159  ...  2933  479  1428  2661  2917  2053  1776  \\\n",
       "0          0.463077 -0.494533  ...     0    0     0     0     0     0     1   \n",
       "1          0.599497 -0.349011  ...     0    0     0     0     0     0     0   \n",
       "2          0.706570 -0.405788  ...     0    0     0     0     1     0     0   \n",
       "3          0.346830 -0.378793  ...     0    0     0     0     0     1     1   \n",
       "4          0.330614 -0.480788  ...     0    0     0     0     0     0     0   \n",
       "...             ...       ...  ...   ...  ...   ...   ...   ...   ...   ...   \n",
       "6919       0.367612 -0.492659  ...     1    0     0     0     0     0     0   \n",
       "6920       0.626327 -0.495895  ...     0    0     0     0     0     1     0   \n",
       "6921       0.513132 -0.370225  ...     0    0     0     0     0     0     0   \n",
       "6922       0.510804 -0.446694  ...     0    0     1     0     0     0     0   \n",
       "6923       0.577548 -0.480602  ...     0    0     0     0     0     0     0   \n",
       "\n",
       "      1120  673  1362  \n",
       "0        0    0     0  \n",
       "1        0    0     0  \n",
       "2        0    0     0  \n",
       "3        0    0     0  \n",
       "4        0    1     0  \n",
       "...    ...  ...   ...  \n",
       "6919     0    0     0  \n",
       "6920     0    0     0  \n",
       "6921     0    0     0  \n",
       "6922     0    0     0  \n",
       "6923     0    0     0  \n",
       "\n",
       "[6924 rows x 756 columns]"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9.441452\n",
       "1       13.146080\n",
       "2       10.085809\n",
       "3       -2.995732\n",
       "4        0.470004\n",
       "          ...    \n",
       "6919     2.397895\n",
       "6920    12.611538\n",
       "6921    12.433208\n",
       "6922     5.323010\n",
       "6923    11.277203\n",
       "Name: Label, Length: 6924, dtype: float64"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d6b5e27d08>]"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(len(Train[\"Label\"])),Train[\"Label\"] )\n",
    "plt.plot(np.arange(len(prediction_train[\"Label_1\"])), prediction_train[\"Label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heamy.dataset import Dataset\n",
    "from heamy.estimator import Regressor, Classifier\n",
    "from heamy.pipeline import ModelsPipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "#加载数据集\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_fold = 5\n",
    "\n",
    "Train = pd.read_csv(\"D:/DC/Molecule_prediction_20200312/train_0312.csv\")\n",
    "\n",
    "##############################################################################################\n",
    "train = Train[[i for i in Train.columns if i not in [\"Features\", \"ID\"]]]\n",
    "# 均值填充none\n",
    "train_x = train.drop(columns=[\"Label\"])\n",
    "\n",
    "\n",
    "#################################################################################################################\n",
    "# -------------------------------------------------特征工程 ---------------------------------------#\n",
    "# 特征 1 \"Features\"\n",
    "def get_Features(Train, train_x):\n",
    "    globals = {\n",
    "            'nan': 0\n",
    "    }\n",
    "    new_col = Train[\"Features\"][train_x.index].apply(lambda x: eval(x, globals))\n",
    "    X = pd.DataFrame(list(new_col.values))\n",
    "#     pca=PCA(n_components=5)\n",
    "#     X_std_pca=pca.fit_transform(X)\n",
    "#     Y=pd.DataFrame(X_std_pca,columns=[\"new_pca_\"+str(i) for i in range(5)])\n",
    "#     train_x = pd.concat([train_x, X,Y], axis=1)\n",
    "    train_x = pd.concat([train_x, X], axis=1)\n",
    "\n",
    "    train_x[\"Features_p\"]       = np.sqrt(np.power(X, 2).sum(axis=1))\n",
    "    train_x[\"Features_mean\"]    = X.mean(axis=1)\n",
    "    train_x[\"Features_min\"]     = X.min(axis=1)\n",
    "    train_x[\"Features_max\"]     = X.max(axis=1)\n",
    "    train_x[\"Features_sum\"]     = X.sum(axis=1)\n",
    "    train_x['Molecular weight'] = np.log1p(train_x['Molecular weight'])\n",
    "    train_x['AlogP']            = np.log1p(train_x['AlogP'])\n",
    "    train_x[\"violations\"]       = train_x[[\"Molecular weight\", \"RO5_violations\"]].mean(axis=1)\n",
    "    \n",
    "    return train_x.fillna(train_x.median())[iport_list]\n",
    "    \n",
    "\n",
    "########################################################################\n",
    "## 获取测试集数据\n",
    "def get_pre():\n",
    "    Test = pd.read_csv(\"D:/DC/Molecule_prediction_20200312/test_noLabel_0312.csv\")\n",
    "    test = Test[[i for i in Test.columns if i not in [\"Features\",\"ID\"]]]\n",
    "    \n",
    "    return get_Features(Test, test),Test[[\"ID\"]]\n",
    "\n",
    "Test_LIST = get_pre()\n",
    "Test=Test_LIST[0]\n",
    "prediction=Test_LIST[1]\n",
    "prediction[\"Label\"] = 0\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# 训练集数据\n",
    "new_train_X = get_Features(Train, train_x)\n",
    "new_train_Y = train[\"Label\"][new_train_X.index]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_train_X, new_train_Y)\n",
    "#创建数据集\n",
    "dataset = Dataset(X_train,y_train,Test)\n",
    "#创建RF模型和LR模型\n",
    "# num_leaves=64,\n",
    "\n",
    "%time model_1 = Regressor(dataset=dataset,estimator = RandomForestRegressor, parameters={'max_depth':7,'min_samples_leaf':7,'n_estimators':50,'random_state':0 })\n",
    "%time model_2 = Regressor(dataset=dataset,estimator = LinearRegression,parameters={'normalize': True})\n",
    "%time model_3 = Regressor(dataset=dataset,estimator = KNeighborsRegressor,parameters={'n_neighbors': 15})\n",
    "%time model_4 = Regressor(dataset=dataset,estimator = LGBMRegressor,parameters={  'max_depth':10,'learning_rate':0.01, 'n_estimators':10000000,'subsample':0.8,'feature_fraction':0.8,'reg_alpha':0.5,'reg_lambda':0.5,'metric':None})\n",
    "\n",
    "\n",
    "# Returns new dataset with out-of-fold predictions\n",
    "%time pipeline = ModelsPipeline(model_1,model_2,model_3,model_4)\n",
    "%time stack_ds = pipeline.stack(k=5)\n",
    "#第二层使用lr模型stack\n",
    "stacker = Regressor(dataset=stack_ds, estimator=LGBMRegressor,parameters={  'max_depth':10,\n",
    "                                                                          'learning_rate':0.01,\n",
    "                                                                          'n_estimators':10000000,\n",
    "                                                                          'subsample':0.8,\n",
    "                                                                          'feature_fraction':0.8,\n",
    "                                                                             'reg_alpha':0.5,\n",
    "                                                                          'reg_lambda':0.5,\n",
    "                                                                          'metric':None})\n",
    "results = stacker.predict()\n",
    "# 使用10折交叉验证结果\n",
    "results10 = stacker.validate(k=5,scorer=mean_squared_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  方法二 通过把异常值和正常值分别训练然后再合成\n",
    "\n",
    "####  效果一般"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对正常值进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_fold = 5\n",
    "\n",
    "Train = pd.read_csv(\"D:/DC/Molecule_prediction_20200312/train_0312.csv\")\n",
    "\n",
    "##############################################################################################\n",
    "train = Train[[i for i in Train.columns if i not in [\"Features\", \"ID\"]]]\n",
    "# 均值填充none\n",
    "train_x = train.drop(columns=[\"Label\"])\n",
    "drop_list=[]\n",
    "\n",
    "#################################################################################################################\n",
    "# -------------------------------------------------特征工程 ---------------------------------------#\n",
    "# 特征 1 \"Features\"\n",
    "def get_Features(Train, train_x):\n",
    "    globals = {\n",
    "            'nan': 0\n",
    "    }\n",
    "    new_col = Train[\"Features\"][train_x.index].apply(lambda x: eval(x, globals))\n",
    "    X = pd.DataFrame(list(new_col.values))\n",
    "    train_x = pd.concat([train_x, X], axis=1)\n",
    "    \n",
    "    train_x[\"Features_p\"]       = np.sqrt(np.power(X, 2).sum(axis=1))\n",
    "    train_x[\"Features_mean\"]    = X.mean(axis=1)\n",
    "    train_x[\"Features_min\"]     = X.min(axis=1)\n",
    "    train_x[\"Features_max\"]     = X.max(axis=1)\n",
    "    train_x[\"Features_sum\"]     = X.sum(axis=1)\n",
    "    train_x['Molecular weight'] = np.log1p(train_x['Molecular weight'])\n",
    "    train_x['AlogP']            = np.log1p(train_x['AlogP'])\n",
    "    train_x[\"violations\"]       = train_x[[\"Molecular weight\", \"RO5_violations\"]].mean(axis=1)\n",
    "    \n",
    "    train_x=train_x.fillna(train_x.median())[iport_list]\n",
    "    \n",
    "    \n",
    "    da = train_x.describe()\n",
    "    keep_list=train_x\n",
    "    for i in ['AlogP', 3166, 3154, 3152, 3157, 3153, 3156, 3161, 'Features_mean']:\n",
    "        IQR = da[i][\"75%\"] - da[i][\"25%\"]\n",
    "        H_iq = da[i][\"75%\"] + 1.5 * IQR\n",
    "        L_iq = da[i][\"25%\"] - 1.5 * IQR\n",
    "        train_x = train_x[(train_x[i] <= H_iq) & (train_x[i] >= L_iq)]\n",
    "    \n",
    "    drop_index=[i for i in keep_list.index if i not in train_x.index]\n",
    "    drop_list .append(keep_list.iloc[drop_index])\n",
    "    \n",
    "    return train_x\n",
    "    \n",
    "\n",
    "########################################################################\n",
    "## 获取测试集数据\n",
    "def get_pre():\n",
    "    Test = pd.read_csv(\"D:/DC/Molecule_prediction_20200312/test_noLabel_0312.csv\")\n",
    "    test = Test[[i for i in Test.columns if i not in [\"Features\",\"ID\"]]]\n",
    "    \n",
    "    return get_Features(Test, test),Test[[\"ID\"]]\n",
    "\n",
    "Test_LIST = get_pre()\n",
    "Test=Test_LIST[0]\n",
    "prediction=Test_LIST[1].iloc[Test.index]\n",
    "prediction[\"Label\"] = 0\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# 训练集数据\n",
    "new_train_X = get_Features(Train, train_x)\n",
    "new_train_Y = train[\"Label\"][new_train_X.index]\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(num_leaves=64,\n",
    "                              max_depth=10,\n",
    "                              learning_rate=0.01,\n",
    "                              n_estimators=10000000,\n",
    "                              subsample=0.8,\n",
    "                              feature_fraction=0.8,\n",
    "                              reg_alpha=0.5,\n",
    "                              reg_lambda=0.5,\n",
    "                              metric=None\n",
    "                              )\n",
    "\n",
    "# 进行交叉验证\n",
    "kfold = KFold(n_splits=n_fold)\n",
    "for train_index, test_index in kfold.split(new_train_X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "    train_x, test_x = new_train_X.iloc[train_index], new_train_X.iloc[test_index]\n",
    "    train_y, test_y = new_train_Y.iloc[train_index], new_train_Y.iloc[test_index]\n",
    "\n",
    "    lgb_model.fit(train_x, train_y,\n",
    "                  eval_set=[(train_x, train_y), (test_x, test_y)],\n",
    "                  eval_metric='rmse',\n",
    "                  verbose=500,\n",
    "                  early_stopping_rounds=50)\n",
    "    \n",
    "    prediction[\"Label\"] += lgb_model.predict(Test, num_iteration=lgb_model.best_iteration_) / n_fold\n",
    "\n",
    "\n",
    "\n",
    "#   测试\n",
    "##############################################################################################\n",
    "# prediction.to_csv('D:/DC/pre_test.csv', index=False)\n",
    "##############################################################################################\n",
    "# iport=pd.DataFrame({\n",
    "#     'column': train_x.columns,\n",
    "#     'importance': lgb_model.feature_importances_,\n",
    "# }).sort_values(ascending=False, by=\"importance\")\n",
    "# iport_list=iport[iport[\"importance\"]>iport.describe().loc[\"50%\"][0]][\"column\"].values\n",
    "# len(iport_list)\n",
    "#############################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    对异常值进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Test=drop_list[0]\n",
    "prediction_2=Test_LIST[1].iloc[Test.index]\n",
    "prediction_2[\"Label\"] = 0\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# 训练集数据\n",
    "new_train_X = drop_list[1]\n",
    "new_train_Y = train[\"Label\"][new_train_X.index]\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(num_leaves=64,\n",
    "                              max_depth=10,\n",
    "                              learning_rate=0.01,\n",
    "                              n_estimators=10000000,\n",
    "                              subsample=0.8,\n",
    "                              feature_fraction=0.8,\n",
    "                              reg_alpha=0.5,\n",
    "                              reg_lambda=0.5,\n",
    "                              metric=None\n",
    "                              )\n",
    "\n",
    "# 进行交叉验证\n",
    "kfold = KFold(n_splits=n_fold)\n",
    "for train_index, test_index in kfold.split(new_train_X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "    train_x, test_x = new_train_X.iloc[train_index], new_train_X.iloc[test_index]\n",
    "    train_y, test_y = new_train_Y.iloc[train_index], new_train_Y.iloc[test_index]\n",
    "\n",
    "    lgb_model.fit(train_x, train_y,\n",
    "                  eval_set=[(train_x, train_y), (test_x, test_y)],\n",
    "                  eval_metric='rmse',\n",
    "                  verbose=500,\n",
    "                  early_stopping_rounds=50)\n",
    "    \n",
    "    prediction_2[\"Label\"] += lgb_model.predict(Test, num_iteration=lgb_model.best_iteration_) / n_fold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_3=Test_LIST[1]\n",
    "prediction_3[\"Label\"] = 0\n",
    "\n",
    "for i in prediction_3.index:\n",
    "    if i in prediction.index:\n",
    "        prediction_3.iloc[i]=prediction.loc[i]\n",
    "    else:\n",
    "        prediction_3.iloc[i]=prediction_2.loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_3.to_csv('D:/DC/pre_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
